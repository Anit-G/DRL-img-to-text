import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Input 
from tensorflow.keras.models import Model
import keras_ocr as ko
rmodel = ko.recognition.Recognizer()
rmodel.compile()
model = rmodel.backbone
my_input_tensor = Input(shape=(66, 660, 1))

# or kerassurgeon for standalone Keras
from kerassurgeon.operations import delete_layer, insert_layer

model = delete_layer(model=model,layer=model.layers[0])
# inserts before layer 0
model = insert_layer(model.layers[0], my_input_tensor)

# model = tf.keras.models.load_model('Model/crnn_kurapan.h5')
model = ko.recognition.Recognizer()
model.compile()
# backbone_weights = model.backbone.get_weights()             # og model without the final FC layer for prediction
# model_weights = model.model.get_weights()                   # Has final FC layer + backbone its a complete model
# train_model_weights = model.training_model.get_weights()    # After model there is an additional CTCDecoder layer
# prediction_weights = model.prediction_model.get_weights()   # Some weird nonsense dont need it

# get the basic backbone model for keras_ocr
DEFAULT_BUILD_PARAMS = {
    "height": 31,
    "width": 200,
    "color": False,
    "filters": (64, 128, 256, 256, 512, 512, 512),
    "rnn_units": (128, 128),
    "dropout": 0.25,
    "rnn_steps_to_discard": 2,
    "pool_size": 2,
    "stn": True,
}
alphabet = string.ascii_lowercase
# new_model,_,_,_ = ko.recognition.build_model(alphabet=string.ascii_lowercase, **DEFAULT_BUILD_PARAMS)
model = model.backbone
model_config = model.get_config()
input_layer_name = model_config['layers'][0]['name']
model_config['layers'][0] = {
                      'name': 'new_input',
                      'class_name': 'InputLayer',
                      'config': {
                          'batch_input_shape': (None, 66,660,1),
                          'dtype': 'float32',
                          'sparse': False,
                          'ragged': False,
                          'name': 'new_input'
                      },
                      'inbound_nodes': []
                  }
model_config['layers'][1]['inbound_nodes'] = [[['new_input', 0, 0, {}]]]
model_config['input_layers'] = [['new_input', 0, 0]]
new_model = model.__class__.from_config(model_config, custom_objects={})

# iterate over all the layers that we want to get weights from
weights = [layer.get_weights() for layer in model.layers[1:]]
for layer, weight in zip(new_model.layers[1:], weights):
    print(layer)
    layer.set_weights(weight)
# inputs = Input(shape=[66,660,1])
# x = model(inputs)
# x = Dense(len(alphabet)+1,kernel_initializer="he_normal",activation="softmax",name="fc_12")(x)
# final_model = Model(input=inputs,outputs=x)
# final_model.summary()




import tensorflow as tf
tf.compat.v1.disable_eager_execution()
sess = tf.compat.v1.Session()
new_saver = tf.compat.v1.train.import_meta_graph('Model/crnn_synth90k/shadownet.ckpt-80000.meta')
new_saver.restore(sess, tf.compat.v1.train.latest_checkpoint('Model/crnn_synth90k/'))
#   print(sess.run('w1:0'))
graph = tf.compat.v1.get_default_graph()
list_of_variables = tf.compat.v1.trainable_variables()
print(len(list_of_variables))
for i in list_of_variables:
    print(i)
    print()






        #Add a transfer learning model from easyocr here
    # load model (keep everything same as an ordinary model except output is basic alphabet and a space)
    model = Model(input_channel=1,output_channel=256,hidden_size=256,num_class=27)
    model_params = torch.load('Model/english_g2.pth',map_location='cpu')

    mp = OrderedDict()
    for key,values in model_params.items():
        key = key.replace('module.','')
        mp[key] = values
        # print(f"{key}: {values.shape}")
    mp['Prediction.weight'] = torch.randn((27, 256)) * 0.01
    mp['Prediction.bias'] = torch.zeros(27)
    model.load_state_dict(mp)

    # change the prediction layer
    # Disable training on all layers except the final prediction layer
    for param in model.parameters():
            param.requires_grad = False
    for param in model.Prediction.parameters():
            param.requires_grad = True
    model.train()